# RAG Application with MilvusDB and Ollama

A production-ready, end-to-end Retrieval-Augmented Generation (RAG) application built with Python, using MilvusDB for vector storage and Ollama for language model inference.

## ğŸŒŸ Features

- ğŸ“„ **Multi-format Document Support**: TXT, PDF, DOCX, and Markdown
- ğŸ” **Efficient Vector Search**: Powered by MilvusDB with IVF_FLAT indexing
- ğŸ¤– **Local LLM Integration**: Uses Ollama (Llama3) for privacy-focused inference
- ğŸ’¬ **Dual Interface**: CLI and REST API server modes
- ğŸŒ **REST API**: FastAPI server with interactive documentation
- ğŸ¯ **Flexible Querying**: Single query, interactive chat, or API calls
- âš™ï¸ **TOML Configuration**: Clean, readable configuration file
- ğŸ“¦ **Installable Package**: Install via pip with CLI commands
- ğŸ§ª **Unit Tests**: Comprehensive test coverage
- ğŸ”„ **Streaming Support**: Real-time response streaming

## ğŸ“ Project Structure

```
rag_application/
â”œâ”€â”€ src/rag_app/              # Main application package
â”‚   â”œâ”€â”€ core/                 # Core functionality
â”‚   â”‚   â”œâ”€â”€ embedding_manager.py
â”‚   â”‚   â”œâ”€â”€ document_processor.py
â”‚   â”‚   â”œâ”€â”€ milvus_manager.py
â”‚   â”‚   â””â”€â”€ rag_pipeline.py
â”‚   â”œâ”€â”€ scripts/              # CLI scripts
â”‚   â”‚   â”œâ”€â”€ ingest.py
â”‚   â”‚   â””â”€â”€ query.py
â”‚   â”œâ”€â”€ utils/                # Utilities
â”‚   â””â”€â”€ config.py             # Configuration
â”œâ”€â”€ tests/                    # Unit tests
â”œâ”€â”€ examples/                 # Usage examples
â”œâ”€â”€ docs/                     # Documentation
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ setup_guide.md
â”‚   â”œâ”€â”€ USAGE.md
â”‚   â””â”€â”€ PROJECT_STRUCTURE.md
â”œâ”€â”€ requirements.txt          # Dependencies
â””â”€â”€ setup.py                  # Package setup
```

## ğŸš€ Quick Start

### Prerequisites

1. **Python 3.8+**
2. **MilvusDB** (via Docker)
3. **Ollama** with a model installed

### Installation

```bash
# Clone the repository
git clone <repository-url>
cd rag_application

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Setup Services

**Start MilvusDB:**
```bash
docker run -d --name milvus_standalone \
  -p 19530:19530 -p 9091:9091 \
  milvusdb/milvus:latest
```

**Start Ollama:**
```bash
# Install Ollama
curl -fsSL https://ollama.com/install.sh | sh

# Pull a model
ollama pull llama2

# Start server
ollama serve
```

### Configuration

Edit `config.toml` to customize settings:

```toml
[ollama]
model = "llama3"  # Change model here

[server]
port = 8000       # Change server port
```

### Usage

#### CLI Mode

**Check Status:**
```bash
python main.py cli status
```

**Ingest Documents:**
```bash
# Create data directory and add documents
mkdir data
# Add your PDF, TXT, DOCX, or MD files

# Ingest documents
python main.py cli ingest ./data/
```

**Query the System:**
```bash
# Interactive chat
python main.py cli query

# Single question
python main.py cli query -q "What is machine learning?"
```

#### Server Mode

**Start the API Server:**
```bash
python main.py server
```

**Access the API:**
- API: http://localhost:8000
- Interactive Docs: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

**Example API Calls:**
```bash
# Query via API
curl -X POST "http://localhost:8000/query" \
  -H "Content-Type: application/json" \
  -d '{"question": "What is AI?", "top_k": 5}'

# Upload document
curl -X POST "http://localhost:8000/documents/upload" \
  -F "file=@document.pdf"

# Ingest documents
curl -X POST "http://localhost:8000/documents/ingest" \
  -H "Content-Type: application/json" \
  -d '{"reset": false}'
```

## ğŸ“š Documentation

- **[Quick Start](QUICKSTART.md)**: Get started in 5 minutes
- **[API Documentation](docs/API_DOCUMENTATION.md)**: Complete API reference
- **[Milvus Setup](docs/MILVUS_SETUP.md)**: Milvus installation and troubleshooting
- **[Project Structure](docs/PROJECT_STRUCTURE.md)**: Codebase organization

## ğŸ”§ Configuration

Configuration is managed via `config.toml`:

```toml
[milvus]
host = "localhost"
port = 19530
collection_name = "rag_documents"

[embedding]
model = "sentence-transformers/all-MiniLM-L6-v2"
dimension = 384

[ollama]
base_url = "http://localhost:11434"
model = "llama3"

# Processing
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
TOP_K=5
```

## ğŸ’» Programmatic Usage

```python
from rag_app import EmbeddingManager, MilvusManager, RAGPipeline

# Initialize components
embedding_manager = EmbeddingManager()
milvus_manager = MilvusManager()
milvus_manager.connect()
milvus_manager.load_collection()

# Create RAG pipeline
rag = RAGPipeline(embedding_manager, milvus_manager)

# Query
result = rag.query("What is AI?", top_k=5)
print(result['response'])
## ğŸ“š Documentation

### Quick Start Guides
- **[MCP_FINAL_SETUP.md](MCP_FINAL_SETUP.md)**: âœ… **START HERE** - Complete working MCP setup
- **[QUICK_START_MCP.md](QUICK_START_MCP.md)**: 5-minute MCP quick start
- **[QUICKSTART.md](QUICKSTART.md)**: General application quick start

### MCP Server Documentation
- **[HOW_TO_USE_MCP.md](HOW_TO_USE_MCP.md)**: Complete MCP usage guide with examples
- **[CLAUDE_DESKTOP_SETUP.md](CLAUDE_DESKTOP_SETUP.md)**: Detailed Claude Desktop setup
- **[MCP_SETUP_GUIDE.md](MCP_SETUP_GUIDE.md)**: General MCP information
- **[docs/MCP_SERVER.md](docs/MCP_SERVER.md)**: Technical MCP API documentation

### General Documentation
- **[API Documentation](docs/API_DOCUMENTATION.md)**: Complete REST API reference
- **[Milvus Setup](docs/MILVUS_SETUP.md)**: Milvus installation and troubleshooting
- **[Project Structure](docs/PROJECT_STRUCTURE.md)**: Codebase organization

```

## ğŸ§ª Testing

```bash
# Run all tests
python -m pytest tests/

# Run with coverage
python -m pytest --cov=src/rag_app tests/
```

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Documents  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Document        â”‚
â”‚ Processor       â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Embedding       â”‚
â”‚ Generator       â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MilvusDB        â”‚
â”‚ (Vector Store)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RAG Pipeline    â”‚â”€â”€â”€â”€â–¶â”‚   Ollama    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Response      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Development

```bash
# Install in development mode
pip install -e .

# Run tests
python -m pytest tests/

# Format code
black src/

# Type checking
mypy src/
```

## ğŸ“¦ Dependencies

- `pymilvus`: Milvus Python SDK
- `sentence-transformers`: Embedding generation
- `ollama`: Ollama Python client
- `pypdf`: PDF processing
- `python-docx`: DOCX processing
- `langchain`: Document utilities

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“„ License

MIT License - see LICENSE file for details

## ğŸ™ Acknowledgments

- [MilvusDB](https://milvus.io/) for vector storage
- [Ollama](https://ollama.ai/) for local LLM inference
- [Sentence-Transformers](https://www.sbert.net/) for embeddings
- [LangChain](https://python.langchain.com/) for document processing

## ğŸ“ Support

- **Documentation**: See `docs/` directory
- **Issues**: GitHub Issues
- **Discussions**: GitHub Discussions

## ğŸ—ºï¸ Roadmap

- [ ] Web interface
- [ ] Conversation history
- [ ] Multiple collection support
- [ ] Advanced filtering
- [ ] Batch processing optimization
- [ ] Docker Compose setup
- [ ] API server

---

**Built with â¤ï¸ for the AI community**